{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENEM 2018\n",
    "For this project, I will be using the dataset used in my [Capstone project](https://github.com/davidsondefaria/Capstone) of the Udacity Data Engineering course. Such dataset is composed of Brazilian demographic and educational data. In this course, I used the knowledge acquired to carry out the ETL process for the dataset.\n",
    "\n",
    "Now, starting the Data Science course, I will perform some analysis on this dataset. I intend to analyze the relationship between the grades obtained in ENEM, the *Exame Nacional do Ensino Médio* (in English 'High School National Exam', an application test for Universities) with the educational HDI of the Brazilian cities.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils import print_pretty\n",
    "from statisticalAnalysis import avgGrade\n",
    "from treatData import treatCities, treatEnem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "In this project, I will be interested in analyzing some influences that location can have on a student who is applying for university. Here are some questions to ask.\n",
    "1. Are the grades obtained in ENEM proportional to the educational HDI of the students' city?\n",
    "2. How can the type of school influence the grade?\n",
    "3. Is there any influence of other HDIs on the grade? (GNI or Life expectancy)\n",
    "4. Is there a difference in the grade of students who live in the same cities and who have a disability compared to those who do not?\n",
    "5. Does the color/race, gender or age of students influence their results or does the influence come from the place and situation in which they live? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding\n",
    "\n",
    "Two datasets of different bases were used:\n",
    "\n",
    "- [Brazil Cities](https://www.kaggle.com/crisparada/brazilian-cities): this dataset is a compilation of data on Brazilian cities taken from different websites. Although there are many interesting fields for analysis, the focus of the project is to prepare a basis for the analysis of HDI data.\n",
    "- [Enem2018](http://portal.inep.gov.br/web/guest/microdados): this dataset presents all the non-sensitive data of the students who took the ENEM 2018. Through it, we can analyze the grades of each student by city, by age, by financial conditions, if they have any disabilities and other specifics.\n",
    "\n",
    "### Source Files\n",
    "The files can be found in [Google Drive](https://drive.google.com/drive/folders/1BoA9AlCZWviPwzGHz71rrIgKCUXGHr2q).\n",
    "\n",
    "- `brazil_cities.csv`: Original dataset about cities.\n",
    "- `brazil_cities_dictionary.csv`: File with subtitles for the dataset columns. \n",
    "- `enem/enem_2018.csv`: Dataset about ENEM 2018. This dataset has previously been reduced its number of columns due to its size. But keeping the original name of the columns in Portuguese.\n",
    "- `enem/enem_2018_dictionary.csv` and `enem/enem_2018_dictionary.xlsx`: Both files have subtitles for ENEM columns. In Portuguese.\n",
    "\n",
    "### Dataset Content\n",
    "The content of the ENEM dataset is already very well organized by INEP, *Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira* (in English National Institute of Educational Studies and Research Anísio Teixeira - it is the federal institute linked to the Brazilian Ministry of Education and aims to promote periodic studies, research and evaluations education system).\n",
    "\n",
    "Although the name of the columns provides a very good semantic sense, they are written in Portuguese, which can make it difficult for those who do not understand the language.\n",
    "\n",
    "There is some missing data that can be easily corrected by assigning values without changing the semantic value of the column. This is due to the fact that the missing data refer to the test scores of students who were not present.\n",
    "\n",
    "Some categorical data has already been worked on by INEP, with integer values that represent real values being assigned. To analyze such data, it is necessary to consult the reference file provided by the institute. However, there are still some categorical data that have not been worked on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Comment this if you have already done the data processing process.\n",
    "\n",
    "# # Original dataset path ENEM\n",
    "# enem_2018_path = os.getcwd() + '/data/original/enem_2018.csv'\n",
    "# enem_2018_df = pd.read_csv(enem_2018_path, delimiter=\";\")\n",
    "\n",
    "# print(enem_2018_df.shape)\n",
    "# enem_2018_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the dataset of Brazilian cities is compiled from public data from multiple sources available in [Kaggle] (https://www.kaggle.com/crisparada/brazilian-cities) that aims to help students who wish improve your analytical skills. As it is a dataset composed of several sources, some data have different update dates. However, the data I want to analyze is all from the same time, which does not influence the final analysis.\n",
    "\n",
    "There are many columns with missing data that could be dealt with by assigning values because it is information that does not exist in cities. However, these data will be taken for final analysis. In addition, there are no categorical data to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Comment this if you have already done the data processing process.\n",
    "\n",
    "# # Original dataset path Brazil Cities\n",
    "# brazil_cities_path = os.getcwd() + '/data/original/brazil_cities.csv'\n",
    "# brazil_cities_df = pd.read_csv(brazil_cities_path, delimiter=\";\")\n",
    "\n",
    "# print(brazil_cities_df.shape)\n",
    "# brazil_cities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data\n",
    "Both datasets contain many columns that do not influence the analysis I want, so I will perform a cleaning process to keep only the columns below. I also renamed the columns.\n",
    "\n",
    "##### Brazil Cities Columns Subtitles\n",
    "\n",
    "|   Columns   |               Legend                  |\n",
    "|-------------|---------------------------------------|\n",
    "|city         |Name of Cities                         |\n",
    "|state        |State of Cities                        |\n",
    "|capital      |Is State Capital?                      |\n",
    "|hdi_ranking  |Human Development Index Ranking        |\n",
    "|hdi          |Human Development Index                |\n",
    "|hdi_gni      |Human Development Index GNI per Capita |\n",
    "|hdi_life     |Human Development Index Life Expectancy|\n",
    "|hdi_education|Human Development Index Educational    |\n",
    "|longitude    |Longitude                              |\n",
    "|latitude     |Latitude                               |\n",
    "|altitude     |Altitude                               |\n",
    "\n",
    "##### Enem 2018 Columns Subtitles\n",
    "\n",
    "|         Columns            | Legend                       |         Columns        | Legend                          |\n",
    "|----------------------------|------------------------------|------------------------|---------------------------------|\n",
    "|registration                |Number of Registration        |def_dyslexia            |Is dyslexic?                     |\n",
    "|city_residence_code         |Code of Residence City        |def_dyscalculia         |Has dyscalculia?                 |\n",
    "|city_residence              |Residence City                |def_autism              |Is autistic?                     |\n",
    "|state_residence_code        |Code of Residence State       |def_monocular_vision    |Has Monocular Vision?            |\n",
    "|state_residence             |Residence State               |def_other               |Has any Other Disability?        |\n",
    "|age                         |Age                           |social_name             |Social Name                      |\n",
    "|gender*                     |Gender                        |city_test_code          |Code of Application City         |\n",
    "|matiral_status*             |Marital Status                |city_test               |Application City                 |\n",
    "|color_race*                 |Color or Race                 |state_test_code         |Code of Application State        |\n",
    "|nationality*                |Nationality                   |state_test              |Application State                |\n",
    "|high_school_status*         |Has finished High School?     |presence_natural_science|Presence in Natural Science Test*|\n",
    "|high_school_year_conclusion*|Year of High School Conclusion|presence_human_science  |Presence in Human Science Test*  |\n",
    "|school_type*                |Type of High School           |presence_languages      |Presence in Languages Test*      |\n",
    "|def_low_vision              |Has Low Vision Deficiency?    |presence_math           |Presence in Math Test*           |\n",
    "|def_blind                   |Is Blind?                     |grade_natural_science   |Grade in Natural Science Test    |\n",
    "|def_deaf                    |Is Deaf?                      |grade_human_science     |Grade in Human Science Test      |\n",
    "|def_low_hearing             |Has Low Hearing Deficiency?   |grade_languages         |Grade in Languages Test          |\n",
    "|def_blind_deaf              |Is Blind and Deaf?            |grade_math              |Grade in Math Test               |\n",
    "|def_physical                |Has Physical Deficiency?      |essay_status            |Essay Status*                    |\n",
    "|def_mental                  |Has Mental Deficiency?        |grade_essay             |Grade in Essay                   |\n",
    "\n",
    "##### \\*Categorical Data Value Legend\n",
    "| value | presence_*             | matiral_status               | high_school_status                                  | school_type    | nationality                 | color_race   |\n",
    "|-------|------------------------|------------------------------|-----------------------------------------------------|----------------|-----------------------------|--------------|\n",
    "| 0     | Missed the test        | Single                       | I already finished high school                      | Uninformed     | Uninformed                  | Not declared |\n",
    "| 1     | Present in the test    | Married/Lives with partner   | I am studying and will finish high school in 2018   | Public school  | Brazilian                   | White        |\n",
    "| 2     | Eliminated in the test | Divorced/Unmarried/Separated | I'm studying and will finish high school after 2018 | Private school | Brazilian Naturalized       | Black        |\n",
    "| 3     |                        | Widowed                      | I haven't finished and I'm not in high school       | Foreign school | Foreigner                   | Parda        |\n",
    "| 4     |                        |                              |                                                     |                | Brazilian born, born abroad | Yellow       |\n",
    "| 5     |                        |                              |                                                     |                |                             | Indigenous   |\n",
    "\n",
    "| value | high_school_year_conclusion | value | high_school_year_conclusion | value | gender |\n",
    "|-------|-----------------------------|-------|-----------------------------|-------|--------|\n",
    "| 0     | Uninformed                  | 7     | 2011                        | M     | Male   |\n",
    "| 1     | 2017                        | 8     | 2010                        | F     | Female |\n",
    "| 2     | 2016                        | 9     | 2009                        |\n",
    "| 3     | 2015                        | 10    | 2008                        |\n",
    "| 4     | 2014                        | 11    | 2007                        |\n",
    "| 5     | 2013                        | 12    | Before 2007                 |\n",
    "| 6     | 2012                        |\n",
    "\n",
    "| value | essay_status                   |\n",
    "|-------|--------------------------------|\n",
    "| 0     |Missed the test                 |\n",
    "| 1     |Smoothly                        |\n",
    "| 2     |Canceled                        |\n",
    "| 3     |Copy Motivating Text            |\n",
    "| 4     |In blank                        |\n",
    "| 6     |Escape to the theme             |\n",
    "| 7     |Non-compliance with textual type|\n",
    "| 8     |Insufficient text               |\n",
    "| 9     |Disconnected party              |\n",
    "\n",
    "\n",
    "### Gathering Data\n",
    "\n",
    "In order to carry out the data processing process of the ENEM dataset, I assigned zero values to the fields due to the fact that they were grades of students who missed the test, removed duplicate data by the enrollment number and renamed the columns to English, but keeping their semantic sense. Also, I kept only the columns I want to analyze. <font size=\"1\">Although the function keeps only the columns I want to analyze, the dataset I made available did not contain any other columns. The dataset provided by INEP was very large and I reduced it to use in the project.</font>\n",
    "\n",
    "For the Brazilian cities dataset, the columns duplicated by city and state were dropped, missing data filled in with zeros, columns renamed for better semantic sense and only columns for analysis were kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Comment this if you have already done the data processing process.\n",
    "\n",
    "# # Data is processed by the functions created in the treatData.py library\n",
    "# treatEnem(enem_2018_path)\n",
    "# treatCities(brazil_cities_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once processed, the data is placed in another folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55138, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registration</th>\n",
       "      <th>city_residence_code</th>\n",
       "      <th>city_residence</th>\n",
       "      <th>state_residence_code</th>\n",
       "      <th>state_residence</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>matiral_status</th>\n",
       "      <th>color_race</th>\n",
       "      <th>nationality</th>\n",
       "      <th>...</th>\n",
       "      <th>presence_natural_science</th>\n",
       "      <th>presence_human_science</th>\n",
       "      <th>presence_languages</th>\n",
       "      <th>presence_math</th>\n",
       "      <th>grade_natural_science</th>\n",
       "      <th>grade_human_science</th>\n",
       "      <th>grade_languages</th>\n",
       "      <th>grade_math</th>\n",
       "      <th>essay_status</th>\n",
       "      <th>grade_essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>180008202043</td>\n",
       "      <td>5300108</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>53</td>\n",
       "      <td>DF</td>\n",
       "      <td>44.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>180008787997</td>\n",
       "      <td>2111300</td>\n",
       "      <td>São Luís</td>\n",
       "      <td>21</td>\n",
       "      <td>MA</td>\n",
       "      <td>17.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>492.2</td>\n",
       "      <td>659.1</td>\n",
       "      <td>587.2</td>\n",
       "      <td>590.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>180008202064</td>\n",
       "      <td>5107958</td>\n",
       "      <td>Tangará da Serra</td>\n",
       "      <td>51</td>\n",
       "      <td>MT</td>\n",
       "      <td>28.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>180008411132</td>\n",
       "      <td>4305108</td>\n",
       "      <td>Caxias do Sul</td>\n",
       "      <td>43</td>\n",
       "      <td>RS</td>\n",
       "      <td>44.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>180008196190</td>\n",
       "      <td>1100338</td>\n",
       "      <td>Nova Mamoré</td>\n",
       "      <td>11</td>\n",
       "      <td>RO</td>\n",
       "      <td>27.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>560.5</td>\n",
       "      <td>572.1</td>\n",
       "      <td>651.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5513300</td>\n",
       "      <td>180013592356</td>\n",
       "      <td>1302504</td>\n",
       "      <td>Manacapuru</td>\n",
       "      <td>13</td>\n",
       "      <td>AM</td>\n",
       "      <td>19.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>447.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5513400</td>\n",
       "      <td>180013075385</td>\n",
       "      <td>1100056</td>\n",
       "      <td>Cerejeiras</td>\n",
       "      <td>11</td>\n",
       "      <td>RO</td>\n",
       "      <td>18.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5513500</td>\n",
       "      <td>180013831993</td>\n",
       "      <td>5002704</td>\n",
       "      <td>Campo Grande</td>\n",
       "      <td>50</td>\n",
       "      <td>MS</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>438.9</td>\n",
       "      <td>514.4</td>\n",
       "      <td>422.3</td>\n",
       "      <td>492.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5513600</td>\n",
       "      <td>180013663323</td>\n",
       "      <td>2408003</td>\n",
       "      <td>Mossoró</td>\n",
       "      <td>24</td>\n",
       "      <td>RN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>484.4</td>\n",
       "      <td>489.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5513700</td>\n",
       "      <td>180013988432</td>\n",
       "      <td>5221403</td>\n",
       "      <td>Trindade</td>\n",
       "      <td>52</td>\n",
       "      <td>GO</td>\n",
       "      <td>21.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>384.2</td>\n",
       "      <td>465.1</td>\n",
       "      <td>437.9</td>\n",
       "      <td>468.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55138 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         registration  city_residence_code    city_residence  \\\n",
       "0        180008202043              5300108          Brasília   \n",
       "100      180008787997              2111300          São Luís   \n",
       "200      180008202064              5107958  Tangará da Serra   \n",
       "300      180008411132              4305108     Caxias do Sul   \n",
       "400      180008196190              1100338       Nova Mamoré   \n",
       "...               ...                  ...               ...   \n",
       "5513300  180013592356              1302504        Manacapuru   \n",
       "5513400  180013075385              1100056        Cerejeiras   \n",
       "5513500  180013831993              5002704      Campo Grande   \n",
       "5513600  180013663323              2408003           Mossoró   \n",
       "5513700  180013988432              5221403          Trindade   \n",
       "\n",
       "         state_residence_code state_residence   age gender  matiral_status  \\\n",
       "0                          53              DF  44.0      M             1.0   \n",
       "100                        21              MA  17.0      M             0.0   \n",
       "200                        51              MT  28.0      F             0.0   \n",
       "300                        43              RS  44.0      F             0.0   \n",
       "400                        11              RO  27.0      F             0.0   \n",
       "...                       ...             ...   ...    ...             ...   \n",
       "5513300                    13              AM  19.0      M             0.0   \n",
       "5513400                    11              RO  18.0      M             0.0   \n",
       "5513500                    50              MS  32.0      M             0.0   \n",
       "5513600                    24              RN  50.0      M             0.0   \n",
       "5513700                    52              GO  21.0      M             0.0   \n",
       "\n",
       "         color_race  nationality  ...  presence_natural_science  \\\n",
       "0                 1            0  ...                       0.0   \n",
       "100               3            1  ...                       1.0   \n",
       "200               3            1  ...                       0.0   \n",
       "300               1            1  ...                       0.0   \n",
       "400               1            1  ...                       1.0   \n",
       "...             ...          ...  ...                       ...   \n",
       "5513300           1            1  ...                       0.0   \n",
       "5513400           3            1  ...                       0.0   \n",
       "5513500           3            1  ...                       1.0   \n",
       "5513600           3            1  ...                       0.0   \n",
       "5513700           3            1  ...                       1.0   \n",
       "\n",
       "         presence_human_science  presence_languages  presence_math  \\\n",
       "0                           0.0                 0.0            0.0   \n",
       "100                         1.0                 1.0            1.0   \n",
       "200                         0.0                 0.0            0.0   \n",
       "300                         0.0                 0.0            0.0   \n",
       "400                         1.0                 1.0            1.0   \n",
       "...                         ...                 ...            ...   \n",
       "5513300                     1.0                 1.0            0.0   \n",
       "5513400                     0.0                 0.0            0.0   \n",
       "5513500                     1.0                 1.0            1.0   \n",
       "5513600                     1.0                 1.0            0.0   \n",
       "5513700                     1.0                 1.0            1.0   \n",
       "\n",
       "         grade_natural_science  grade_human_science  grade_languages  \\\n",
       "0                          0.0                  0.0              0.0   \n",
       "100                      492.2                659.1            587.2   \n",
       "200                        0.0                  0.0              0.0   \n",
       "300                        0.0                  0.0              0.0   \n",
       "400                      543.0                560.5            572.1   \n",
       "...                        ...                  ...              ...   \n",
       "5513300                    0.0                403.0            447.6   \n",
       "5513400                    0.0                  0.0              0.0   \n",
       "5513500                  438.9                514.4            422.3   \n",
       "5513600                    0.0                484.4            489.9   \n",
       "5513700                  384.2                465.1            437.9   \n",
       "\n",
       "         grade_math  essay_status  grade_essay  \n",
       "0               0.0           0.0          0.0  \n",
       "100           590.5           1.0        920.0  \n",
       "200             0.0           0.0          0.0  \n",
       "300             0.0           0.0          0.0  \n",
       "400           651.3           1.0        480.0  \n",
       "...             ...           ...          ...  \n",
       "5513300         0.0           1.0        380.0  \n",
       "5513400         0.0           0.0          0.0  \n",
       "5513500       492.9           1.0        260.0  \n",
       "5513600         0.0           4.0          0.0  \n",
       "5513700       468.3           1.0        280.0  \n",
       "\n",
       "[55138 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processed dataset path ENEM\n",
    "enem_analysis_path = os.getcwd() + '/data/analysis/enem_analysis.csv'\n",
    "enem_analysis_df = pd.read_csv(enem_analysis_path, delimiter=\";\")\n",
    "\n",
    "# If you want to perform a quick test, uncomment this line.\n",
    "# This line takes only 1% of the dataset evenly.\n",
    "enem_analysis_df = enem_analysis_df.drop(enem_analysis_df.index.difference([x for x in range(0, len(enem_analysis_df), 100)]))\n",
    "\n",
    "print(enem_analysis_df.shape)\n",
    "enem_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5573, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>capital</th>\n",
       "      <th>hdi_ranking</th>\n",
       "      <th>hdi</th>\n",
       "      <th>hdi_gni</th>\n",
       "      <th>hdi_life</th>\n",
       "      <th>hdi_education</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>altitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Abadia De Goiás</td>\n",
       "      <td>GO</td>\n",
       "      <td>0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.622</td>\n",
       "      <td>-49.440548</td>\n",
       "      <td>-16.758812</td>\n",
       "      <td>893.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Abadia Dos Dourados</td>\n",
       "      <td>MG</td>\n",
       "      <td>0</td>\n",
       "      <td>2207.0</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.563</td>\n",
       "      <td>-47.396832</td>\n",
       "      <td>-18.487565</td>\n",
       "      <td>753.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Abadiânia</td>\n",
       "      <td>GO</td>\n",
       "      <td>0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.579</td>\n",
       "      <td>-48.718812</td>\n",
       "      <td>-16.182672</td>\n",
       "      <td>1017.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Abaeté</td>\n",
       "      <td>MG</td>\n",
       "      <td>0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.556</td>\n",
       "      <td>-45.446191</td>\n",
       "      <td>-19.155848</td>\n",
       "      <td>644.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Abaetetuba</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.537</td>\n",
       "      <td>-48.884404</td>\n",
       "      <td>-1.723470</td>\n",
       "      <td>10.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5568</td>\n",
       "      <td>Xique-Xique</td>\n",
       "      <td>BA</td>\n",
       "      <td>0</td>\n",
       "      <td>4533.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.479</td>\n",
       "      <td>-42.725508</td>\n",
       "      <td>-10.824974</td>\n",
       "      <td>406.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5569</td>\n",
       "      <td>Zabelê</td>\n",
       "      <td>PB</td>\n",
       "      <td>0</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.587</td>\n",
       "      <td>-37.093552</td>\n",
       "      <td>-8.076874</td>\n",
       "      <td>646.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5570</td>\n",
       "      <td>Zacarias</td>\n",
       "      <td>SP</td>\n",
       "      <td>0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.674</td>\n",
       "      <td>-50.055740</td>\n",
       "      <td>-21.050110</td>\n",
       "      <td>415.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5571</td>\n",
       "      <td>Zé Doca</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>4272.0</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-45.657698</td>\n",
       "      <td>-3.275481</td>\n",
       "      <td>35.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5572</td>\n",
       "      <td>Zortéa</td>\n",
       "      <td>SC</td>\n",
       "      <td>0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.661</td>\n",
       "      <td>-51.549566</td>\n",
       "      <td>-27.450251</td>\n",
       "      <td>685.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5573 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     city state  capital  hdi_ranking    hdi  hdi_gni  \\\n",
       "0         Abadia De Goiás    GO        0       1689.0  0.708    0.687   \n",
       "1     Abadia Dos Dourados    MG        0       2207.0  0.690    0.693   \n",
       "2               Abadiânia    GO        0       2202.0  0.690    0.671   \n",
       "3                  Abaeté    MG        0       1994.0  0.698    0.720   \n",
       "4              Abaetetuba    PA        0       3530.0  0.628    0.579   \n",
       "...                   ...   ...      ...          ...    ...      ...   \n",
       "5568          Xique-Xique    BA        0       4533.0  0.585    0.563   \n",
       "5569               Zabelê    PB        0       3639.0  0.623    0.567   \n",
       "5570             Zacarias    SP        0       1072.0  0.730    0.695   \n",
       "5571              Zé Doca    MA        0       4272.0  0.595    0.559   \n",
       "5572               Zortéa    SC        0        364.0  0.760    0.752   \n",
       "\n",
       "      hdi_life  hdi_education  longitude   latitude  altitude  \n",
       "0        0.830          0.622 -49.440548 -16.758812    893.60  \n",
       "1        0.839          0.563 -47.396832 -18.487565    753.12  \n",
       "2        0.841          0.579 -48.718812 -16.182672   1017.55  \n",
       "3        0.848          0.556 -45.446191 -19.155848    644.74  \n",
       "4        0.798          0.537 -48.884404  -1.723470     10.12  \n",
       "...        ...            ...        ...        ...       ...  \n",
       "5568     0.741          0.479 -42.725508 -10.824974    406.26  \n",
       "5569     0.725          0.587 -37.093552  -8.076874    646.34  \n",
       "5570     0.826          0.674 -50.055740 -21.050110    415.85  \n",
       "5571     0.745          0.505 -45.657698  -3.275481     35.66  \n",
       "5572     0.885          0.661 -51.549566 -27.450251    685.30  \n",
       "\n",
       "[5573 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processed dataset path Brazil Cities\n",
    "cities_analysis_path = os.getcwd() + '/data/analysis/cities_analysis.csv'\n",
    "cities_analysis_df = pd.read_csv(cities_analysis_path, delimiter=\";\")\n",
    "\n",
    "print(cities_analysis_df.shape)\n",
    "cities_analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wangling Data\n",
    "In order to answer the questions asked in step 1, we are going to define some functions to start working with the data to get what we want.\\\n",
    "<font size=\"1\">At this point, it would be interesting to use a database to facilitate the integration of the two datasets, however, I will be using only python to browse the files for learning purposes.</font>\n",
    "\n",
    "The `statisticalAnalysis.py` library contains functions for performing statistical analysis. Starting in an easy way, we will average the tests and analyze the highest and lowest grades:\n",
    "- `avgGrade`: Returns average grade of each test.\n",
    "    - Parameters:\n",
    "        - *enem (pandas dataframe)*: ENEM dataframe that contains all grades.\n",
    "        - *onlyPresent (boolean)*: TRUE if you only want the grades of the students who took the test. FALSE if you want all the grades.\n",
    "    - Returns:\n",
    "        - Dictionary with test content and their respective averages, min e max grades.\n",
    "\n",
    "In order to answer the first question in step 1, the `gradeHDIRelation` function relates the grades to the educational HDI of each city:\n",
    "- `gradeHDIRelation`: \n",
    "    - Parameters:\n",
    "        - * *:\n",
    "    - Returns:\n",
    "        - A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Model\n",
    "For this project, I will not be applying any artificial intelligence algorithm, but only statistical analysis. So there is nothing special about this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Results\n",
    "\n",
    "Average student grades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resAll = avgGrade(enem_analysis_df, onlyPresent=False)\n",
    "resPresent = avgGrade(enem_analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average grades of all students:\n",
      "---------------  -------  -----  -----\n",
      "content             mean    min    max\n",
      "---------------  -------  -----  -----\n",
      "natural_science  349.653      0  819\n",
      "human_science    427.945      0  821\n",
      "languages        396.418      0  792.7\n",
      "math             379.21       0  988.4\n",
      "essay            382.517      0  980\n",
      "\n",
      "Average grades of students who took the test:\n",
      "---------------  ----------  -------  -----  -----\n",
      "content            presence     mean    min    max\n",
      "---------------  ----------  -------  -----  -----\n",
      "natural_science       39144  492.518      0  819\n",
      "human_science         41595  567.281      0  821\n",
      "languages             41595  525.489      0  792.7\n",
      "math                  39144  534.153      0  988.4\n",
      "essay                 41574  507.318      0  980\n"
     ]
    }
   ],
   "source": [
    "print('Average grades of all students:\\n---------------  -------  -----  -----')\n",
    "print_pretty(resAll, tabular=True)\n",
    "print('\\nAverage grades of students who took the test:\\n---------------  ----------  -------  -----  -----')\n",
    "print_pretty(resPresent, tabular=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
